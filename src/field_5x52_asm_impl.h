/**
 * Generated by CryptOpt (https://github.com/0xADE1A1DE/CryptOpt)
 */

#ifndef SECP256K1_FIELD_INNER5X52_IMPL_H
#define SECP256K1_FIELD_INNER5X52_IMPL_H

#include "util.h"

SECP256K1_INLINE static void
secp256k1_fe_mul_inner(uint64_t *r, const uint64_t *a, const uint64_t *SECP256K1_RESTRICT b) {
  uint64_t tmp0, tmp1, tmp2, tmp3;
  __asm__ __volatile__(
    "mov    %%rdx,%%rax\n"
    "mov    0x10(%%rdx),%%rdx\n"
    "mulx   0x8(%%rsi),%%r10,%%r11\n"
    "mov    0x20(%%rax),%%rdx\n"
    "mulx   0x20(%%rsi),%%rcx,%%r8\n"
    "mov    (%%rax),%%rdx\n"
    "mulx   0x18(%%rsi),%%r9,%%rbx\n"
    "mov    0x10(%%rsi),%%rdx\n"
    "mulx   0x8(%%rax),%%r12,%%r13\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r12,%%r9\n"
    "adox   %%rbx,%%r13\n"
    "mov    0x18(%%rax),%%rdx\n"
    "mulx   (%%rsi),%%rbx,%%r12\n"
    "adcx   %%r10,%%r9\n"
    "adcx   %%r13,%%r11\n"
    "add    %%rbx,%%r9\n"
    "adcx   %%r11,%%r12\n"
    "mov    0x18(%%rsi),%%rdx\n"
    "mulx   0x8(%%rax),%%r10,%%r13\n"
    "mov    (%%rax),%%rdx\n"
    "mulx   0x20(%%rsi),%%rbx,%%r11\n"
    "movabs $0x1000003d10,%%rdx\n"
    "mulx   %%rcx,%%r14,%%r15\n"
    "add    %%r9,%%r14\n"
    "adcx   %%r15,%%r12\n"
    "mov    %%r14,%%r9\n"
    "shrd   $0x34,%%r12,%%r9\n"
    "mov    0x10(%%rsi),%%rdx\n"
    "mulx   0x10(%%rax),%%rcx,%%r15\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r10,%%rbx\n"
    "adox   %%r11,%%r13\n"
    "adcx   %%rcx,%%rbx\n"
    "adcx   %%r13,%%r15\n"
    "mov    0x18(%%rax),%%rdx\n"
    "mulx   0x8(%%rsi),%%r10,%%r11\n"
    "add    %%r10,%%rbx\n"
    "adcx   %%r15,%%r11\n"
    "mov    (%%rsi),%%rdx\n"
    "mulx   0x20(%%rax),%%r12,%%rcx\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r12,%%rbx\n"
    "adox   %%r11,%%rcx\n"
    "movabs $0x1000003d10000,%%r13\n"
    "mov    %%r13,%%rdx\n"
    "mulx   %%r8,%%r13,%%r15\n"
    "adcx   %%r9,%%rbx\n"
    "adc    $0x0,%%rcx\n"
    "add    %%rbx,%%r13\n"
    "adcx   %%r15,%%rcx\n"
    "movabs $0xfffffffffffff,%%r8\n"
    "mov    %%r13,%%r9\n"
    "and    %%r8,%%r9\n"
    "mov    %%r9,%%r10\n"
    "shr    $0x30,%%r10\n"
    "mov    0x18(%%rsi),%%rdx\n"
    "mulx   0x10(%%rax),%%r11,%%r12\n"
    "mov    0x20(%%rsi),%%rdx\n"
    "mulx   0x8(%%rax),%%r15,%%rbx\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r11,%%r15\n"
    "adox   %%rbx,%%r12\n"
    "mov    0x10(%%rsi),%%rdx\n"
    "mulx   0x18(%%rax),%%r11,%%rbx\n"
    "adcx   %%r11,%%r15\n"
    "adcx   %%r12,%%rbx\n"
    "mov    0x8(%%rsi),%%rdx\n"
    "mulx   0x20(%%rax),%%r12,%%r11\n"
    "mov    0x18(%%rax),%%rdx\n"
    "mov    %%rdi,%q0\n"
    "mulx   0x18(%%rsi),%%r8,%%rdi\n"
    "shrd   $0x34,%%rcx,%%r13\n"
    "add    %%r12,%%r15\n"
    "adcx   %%rbx,%%r11\n"
    "mov    0x20(%%rsi),%%rdx\n"
    "mulx   0x10(%%rax),%%rcx,%%rbx\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r13,%%r15\n"
    "adox   %%rdx,%%r11\n"
    "mov    %%r15,%%r12\n"
    "shrd   $0x34,%%r11,%%r12\n"
    "xor    %%r13,%%r13\n"
    "adox   %%r8,%%rcx\n"
    "adox   %%rbx,%%rdi\n"
    "mov    0x10(%%rsi),%%rdx\n"
    "mulx   0x20(%%rax),%%r8,%%rbx\n"
    "adcx   %%r8,%%rcx\n"
    "adcx   %%rdi,%%rbx\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r12,%%rcx\n"
    "adox   %%rdx,%%rbx\n"
    "movabs $0xfffffffffffff,%%r13\n"
    "and    %%r13,%%r15\n"
    "shl    $0x4,%%r15\n"
    "mov    %%rcx,%%r11\n"
    "shrd   $0x34,%%rbx,%%r11\n"
    "lea    (%%r10,%%r15,1),%%r10\n"
    "movabs $0x1000003d1,%%r12\n"
    "mov    %%r10,%%rdx\n"
    "mulx   %%r12,%%r10,%%rdi\n"
    "movabs $0xffffffffffff,%%r8\n"
    "and    %%r8,%%r9\n"
    "mov    (%%rax),%%rdx\n"
    "mulx   0x8(%%rsi),%%rbx,%%r15\n"
    "mov    (%%rax),%%rdx\n"
    "mulx   (%%rsi),%%r8,%%r12\n"
    "adox   %%r8,%%r10\n"
    "adox   %%rdi,%%r12\n"
    "mov    0x8(%%rax),%%rdx\n"
    "mulx   (%%rsi),%%rdi,%%r8\n"
    "mov    0x8(%%rsi),%%rdx\n"
    "mov    %%r9,%q1\n"
    "mulx   0x8(%%rax),%%r13,%%r9\n"
    "mov    0x18(%%rax),%%rdx\n"
    "mov    %%r9,%q2\n"
    "mov    %%r13,%q3\n"
    "mulx   0x20(%%rsi),%%r9,%%r13\n"
    "mov    %%r10,%%rdx\n"
    "shrd   $0x34,%%r12,%%rdx\n"
    "add    %%rdi,%%rbx\n"
    "adcx   %%r15,%%r8\n"
    "add    %%rdx,%%rbx\n"
    "adc    $0x0,%%r8\n"
    "mov    0x20(%%rax),%%rdx\n"
    "mulx   0x18(%%rsi),%%r15,%%r12\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r15,%%r9\n"
    "adox   %%r13,%%r12\n"
    "adcx   %%r11,%%r9\n"
    "adc    $0x0,%%r12\n"
    "mov    0x10(%%rax),%%rdx\n"
    "mulx   (%%rsi),%%r11,%%rdi\n"
    "movabs $0xfffffffffffff,%%rdx\n"
    "and    %%rdx,%%rcx\n"
    "movabs $0x1000003d10,%%r13\n"
    "mov    %%r13,%%rdx\n"
    "mulx   %%rcx,%%r13,%%r15\n"
    "adox   %%rbx,%%r13\n"
    "adox   %%r15,%%r8\n"
    "mulx   %%r9,%%rbx,%%rcx\n"
    "mov    (%%rax),%%rdx\n"
    "mulx   0x10(%%rsi),%%r9,%%r15\n"
    "adcx   %q3,%%r9\n"
    "adcx   %q2,%%r15\n"
    "mov    %%r13,%%rdx\n"
    "shrd   $0x34,%%r8,%%rdx\n"
    "xor    %%r8,%%r8\n"
    "adox   %%r11,%%r9\n"
    "adox   %%r15,%%rdi\n"
    "adcx   %%rdx,%%r9\n"
    "adc    $0x0,%%rdi\n"
    "movabs $0xfffffffffffff,%%r11\n"
    "and    %%r11,%%r10\n"
    "adox   %%r9,%%rbx\n"
    "adox   %%rcx,%%rdi\n"
    "mov    %%rbx,%%rcx\n"
    "and    %%r11,%%rcx\n"
    "shrd   $0x34,%%rdi,%%rbx\n"
    "mov    %q0,%%r15\n"
    "mov    %%r10,(%%r15)\n"
    "and    %%r11,%%r14\n"
    "movabs $0x1000003d10000,%%rdx\n"
    "mulx   %%r12,%%r9,%%r10\n"
    "lea    (%%rbx,%%r14,1),%%rbx\n"
    "adox   %%rbx,%%r9\n"
    "adox   %%r8,%%r10\n"
    "mov    %%r9,%%r12\n"
    "and    %%r11,%%r12\n"
    "mov    %%r12,0x18(%%r15)\n"
    "shrd   $0x34,%%r10,%%r9\n"
    "add    %q1,%%r9\n"
    "mov    %%r9,0x20(%%r15)\n"
    "and    %%r11,%%r13\n"
    "mov    %%r13,0x8(%%r15)\n"
    "mov    %%rcx,0x10(%%r15)\n"

    : "=&m"(tmp0), "=&m"(tmp1), "=&m"(tmp2), "=&m"(tmp3), "+D"(r), "+d"(b)
    : "S"(a)
    : "rax", "rbx", "rcx",  "r8", "r9", "r10", "r11", "r12", "r13",
      "r14", "r15", "cc", "memory");
}

SECP256K1_INLINE static void secp256k1_fe_sqr_inner(uint64_t *r, const uint64_t *a) {

  uint64_t tmp0, tmp1;
  __asm__ __volatile__(

    "mov    (%%rsi),%%rax\n"
    "lea    (%%rax,%%rax,1),%%r10\n"
    "mov    0x18(%%rsi),%%rdx\n"
    "mulx   %%r10,%%rax,%%r11\n"
    "mov    0x20(%%rsi),%%rdx\n"
    "mulx   %%rdx,%%rcx,%%r8\n"
    "mov    0x8(%%rsi),%%rdx\n"
    "lea    (%%rdx,%%rdx,1),%%r9\n"
    "mov    0x10(%%rsi),%%rdx\n"
    "mulx   %%r9,%%rbx,%%r12\n"
    "mov    0x10(%%rsi),%%rdx\n"
    "mov    %%rdx,%%r13\n"
    "shl    %%r13\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%rax,%%rbx\n"
    "adox   %%r12,%%r11\n"
    "movabs $0x1000003d10,%%rax\n"
    "mov    %%rcx,%%rdx\n"
    "mulx   %%rax,%%rcx,%%r12\n"
    "adcx   %%rbx,%%rcx\n"
    "adcx   %%r12,%%r11\n"
    "mov    0x10(%%rsi),%%rdx\n"
    "mulx   %%rdx,%%rbx,%%r12\n"
    "mov    0x18(%%rsi),%%rdx\n"
    "mulx   %%r9,%%r14,%%r15\n"
    "mov    %%rcx,%%rdx\n"
    "shrd   $0x34,%%r11,%%rdx\n"
    "xor    %%r11,%%r11\n"
    "adox   %%r14,%%rbx\n"
    "adox   %%r12,%%r15\n"
    "mov    %%rdx,%%r12\n"
    "mov    0x20(%%rsi),%%rdx\n"
    "mulx   %%r10,%%r14,%%r11\n"
    "adcx   %%r14,%%rbx\n"
    "adcx   %%r15,%%r11\n"
    "movabs $0x1000003d10000,%%rdx\n"
    "mulx   %%r8,%%r15,%%r14\n"
    "xor    %%r8,%%r8\n"
    "adox   %%r12,%%rbx\n"
    "adox   %%r8,%%r11\n"
    "adcx   %%rbx,%%r15\n"
    "adcx   %%r14,%%r11\n"
    "mov    %%r15,%%r12\n"
    "shrd   $0x34,%%r11,%%r12\n"
    "movabs $0xfffffffffffff,%%r14\n"
    "and    %%r14,%%rcx\n"
    "mov    %%r9,%%rdx\n"
    "mulx   0x20(%%rsi),%%r9,%%rbx\n"
    "mov    %%r13,%%rdx\n"
    "mulx   0x18(%%rsi),%%r13,%%r11\n"
    "adox   %%r9,%%r13\n"
    "adox   %%r11,%%rbx\n"
    "adcx   %%r12,%%r13\n"
    "adc    $0x0,%%rbx\n"
    "mov    %%r13,%%r12\n"
    "and    %%r14,%%r12\n"
    "mulx   0x20(%%rsi),%%r9,%%r11\n"
    "shrd   $0x34,%%rbx,%%r13\n"
    "mov    0x18(%%rsi),%%rdx\n"
    "mulx   %%rdx,%%rbx,%%r8\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r9,%%rbx\n"
    "adox   %%r8,%%r11\n"
    "adcx   %%r13,%%rbx\n"
    "adc    $0x0,%%r11\n"
    "mov    %%rbx,%%r9\n"
    "shrd   $0x34,%%r11,%%r9\n"
    "imul   $0x2,0x18(%%rsi),%%r13\n"
    "and    %%r14,%%r15\n"
    "and    %%r14,%%rbx\n"
    "mov    0x20(%%rsi),%%rdx\n"
    "mulx   %%r13,%%r8,%%r11\n"
    "mov    %%r15,%%rdx\n"
    "shr    $0x30,%%rdx\n"
    "shl    $0x4,%%r12\n"
    "lea    (%%rdx,%%r12,1),%%rdx\n"
    "movabs $0x1000003d1,%%r13\n"
    "mulx   %%r13,%%r12,%%r14\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r9,%%r8\n"
    "adox   %%rdx,%%r11\n"
    "mov    (%%rsi),%%rdx\n"
    "mulx   %%rdx,%%r9,%%r13\n"
    "adcx   %%r9,%%r12\n"
    "adcx   %%r14,%%r13\n"
    "mov    %%rax,%%rdx\n"
    "mulx   %%rbx,%%rax,%%r14\n"
    "mov    %%r12,%%rbx\n"
    "shrd   $0x34,%%r13,%%rbx\n"
    "mulx   %%r8,%%r9,%%r13\n"
    "mov    %%r10,%%rdx\n"
    "mulx   0x10(%%rsi),%%r10,%%r8\n"
    "mov    %%rdi,%q0\n"
    "mov    %%r11,%q1\n"
    "mulx   0x8(%%rsi),%%rdi,%%r11\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%rbx,%%rdi\n"
    "adox   %%rdx,%%r11\n"
    "adcx   %%rdi,%%rax\n"
    "adcx   %%r14,%%r11\n"
    "movabs $0xfffffffffffff,%%r14\n"
    "and    %%r14,%%r12\n"
    "mov    %%rax,%%rbx\n"
    "shrd   $0x34,%%r11,%%rbx\n"
    "mov    %q0,%%rdi\n"
    "mov    %%r12,(%%rdi)\n"
    "mov    0x8(%%rsi),%%rdx\n"
    "mulx   %%rdx,%%r11,%%r12\n"
    "xor    %%rdx,%%rdx\n"
    "adox   %%r10,%%r11\n"
    "adox   %%r12,%%r8\n"
    "adcx   %%rbx,%%r11\n"
    "adc    $0x0,%%r8\n"
    "add    %%r11,%%r9\n"
    "adcx   %%r13,%%r8\n"
    "mov    %%r9,%%r13\n"
    "shrd   $0x34,%%r8,%%r13\n"
    "lea    0x0(%%r13,%%rcx,1),%%r13\n"
    "movabs $0x1000003d10000,%%rcx\n"
    "mov    %%rcx,%%rdx\n"
    "mulx   %q1,%%rcx,%%r10\n"
    "add    %%r13,%%rcx\n"
    "adc    $0x0,%%r10\n"
    "mov    %%rcx,%%rbx\n"
    "shrd   $0x34,%%r10,%%rbx\n"
    "and    %%r14,%%rax\n"
    "mov    %%rax,0x8(%%rdi)\n"
    "movabs $0xffffffffffff,%%r12\n"
    "and    %%r12,%%r15\n"
    "lea    (%%rbx,%%r15,1),%%rbx\n"
    "and    %%r14,%%rcx\n"
    "and    %%r14,%%r9\n"
    "mov    %%r9,0x10(%%rdi)\n"
    "mov    %%rcx,0x18(%%rdi)\n"
    "mov    %%rbx,0x20(%%rdi)\n"

    : "=&m"(tmp0), "=&m"(tmp1),  "+D"(r)
    : "D"(r), "S"(a)
    : "rax", "rbx", "rcx", "rdx", "r8", "r9", "r10", "r11", "r12",
      "r13", "r14", "r15", "cc", "memory");
}
#endif
